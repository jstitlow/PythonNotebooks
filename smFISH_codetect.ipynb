{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating co-detection percentage for threshold = 300 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "codetection %:  32.5057885259\n",
      "calculating co-detection percentage for threshold = 500 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "codetection %:  35.4000514536\n"
     ]
    }
   ],
   "source": [
    "############################################################################# \n",
    "# Calculate percentage of spots detected by separate smFISH probes           \n",
    "# Josh Titlow- November 30, 2018                                            \n",
    "#                                                                            \n",
    "# Requires 2 folders with output files from FISHquant analysis              \n",
    "# ******NOTE****** need to delete last row of file SPOTS_END                \n",
    "#      -files should have the same name                                     \n",
    "#      -passed as command line arguments                                    \n",
    "#      -ch1_indir                                                               \n",
    "#      -ch2_indir                                                           \n",
    "#                                                                           \n",
    "# Requires threshold distance (in nm) for assigning co-detection            \n",
    "#      -passed as command line argument                                         \n",
    "#      -threshold                                                           \n",
    "#      -300nm is reasonable                                                 \n",
    "#    \n",
    "# Cell below has code for co-detection with output from 3D object counter   \n",
    "#        \n",
    "# TODO                                                                     \n",
    "# add output from                                                               \n",
    "#############################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# specify the FQ centroid files and co-detection distance threshold in nm\n",
    "indir = '/Users/joshtitlow/tmp/smFISH_data/codetect/'\n",
    "infiles = os.listdir(indir)\n",
    "\n",
    "\n",
    "\n",
    "#threshold_range = [50,100,150,200,250,300,350,400,450,500] \n",
    "threshold_range = [300,500]\n",
    "\n",
    "# create list to store data\n",
    "filename = []\n",
    "co_detect = []\n",
    "ch1_spots = []\n",
    "ch2_spots = []\n",
    "threshold = []\n",
    "\n",
    "for t in threshold_range:\n",
    "    print \"calculating co-detection percentage for threshold =\", t, \"nm\"\n",
    "    # loop through files\n",
    "    for i in infiles:\n",
    "        if i.startswith('C2'):\n",
    "            if i.endswith('spots.txt'):\n",
    "                ref_file = os.path.join(indir,i)\n",
    "                #print \"processing\", i, \"for threshold =\", t\n",
    "                ref_file = pd.read_csv(ref_file, sep='\\t', header=18)\n",
    "                #ref_file = ref_file[~ref_file.Pos_Y.str.contains(\"SPOTS_END\")]\n",
    "                targ_file = os.path.join(indir, 'C4'+i[2:])\n",
    "                print targ_file\n",
    "                targ_file = pd.read_csv(targ_file, sep='\\t', header=18)\n",
    "    \n",
    "                # get centroid coordinates\n",
    "                xpos_ref = ref_file['Pos_X']\n",
    "                ypos_ref = ref_file['Pos_Y']\n",
    "                zpos_ref = ref_file['Pos_Z']\n",
    "\n",
    "                xpos_targ = targ_file['Pos_X']\n",
    "                ypos_targ = targ_file['Pos_Y']\n",
    "                zpos_targ = targ_file['Pos_Z']\n",
    "\n",
    "                # convert data into a numpy array\n",
    "                target_df = np.column_stack((xpos_targ,ypos_targ,zpos_targ))\n",
    "                #target_df = [target_df.Pos_Y.str.contains(\"SPOTS_END\") == False]\n",
    "\n",
    "                # create list to store amplitude of co-detected spot, ref/targ ratio, and target distance\n",
    "                targ_amp = []\n",
    "                targ_dist = []\n",
    "\n",
    "                for index, row in ref_file.iterrows():\n",
    "\n",
    "                    # get 3D position from X,Y,Z position columns\n",
    "                    pt  = float(row['Pos_X']), float(row['Pos_Y']), float(row['Pos_Z'])\n",
    "                    # find nearest neighbor and calculate distance\n",
    "                    distance,index = spatial.KDTree(target_df).query(pt)\n",
    "\n",
    "                    # add nearest neighbor amp and dist to a list\n",
    "                    targ_amp.append(targ_file['AMP'].iloc[index])\n",
    "                    targ_dist.append(distance)\n",
    "\n",
    "                # add lists to ref_file\n",
    "                ref_file['target_amp'] = targ_amp\n",
    "                ref_file['r_t_ratio'] = ref_file['AMP'].div(targ_amp)\n",
    "                ref_file['targ_dist'] = targ_dist\n",
    "\n",
    "                # calculate co-detection percentage and add it to list\n",
    "                codetect = 100 * (float(len(ref_file[ref_file.targ_dist < float(t)])))/(float(len(ref_file.index)))\n",
    "                print 'codetection %: ', codetect\n",
    "                co_detect.append(codetect)\n",
    "\n",
    "                # calculate number of spots and add to list, with filename\n",
    "                ch1_spots.append(len(ref_file))\n",
    "                ch2_spots.append(len(targ_file))\n",
    "                filename.append(i)\n",
    "                threshold.append(t)\n",
    "\n",
    "                # write ref_file to csv\n",
    "                #ref_file.to_csv('test_list.csv', index=False)\n",
    "\n",
    "# add data to dataframe and save\n",
    "df = pd.DataFrame({'filename':filename, 'threshold':threshold, 'co_detect':co_detect, 'ch1_spots':ch1_spots, 'ch2_spots':ch2_spots})\n",
    "df = df[['filename', 'threshold', 'co_detect', 'ch1_spots', 'ch2_spots']]\n",
    "df.to_csv('codetection_stats.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos_Y</th>\n",
       "      <th>Pos_X</th>\n",
       "      <th>Pos_Z</th>\n",
       "      <th>AMP</th>\n",
       "      <th>BGD</th>\n",
       "      <th>RES</th>\n",
       "      <th>SigmaX</th>\n",
       "      <th>SigmaY</th>\n",
       "      <th>SigmaZ</th>\n",
       "      <th>Cent_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_max</th>\n",
       "      <th>INT_raw</th>\n",
       "      <th>INT_filt</th>\n",
       "      <th>SC_det</th>\n",
       "      <th>SC_det_norm</th>\n",
       "      <th>TH_det</th>\n",
       "      <th>TH_fit</th>\n",
       "      <th>target_amp</th>\n",
       "      <th>r_t_ratio</th>\n",
       "      <th>targ_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28679.00</td>\n",
       "      <td>553.786</td>\n",
       "      <td>795.715</td>\n",
       "      <td>705.514</td>\n",
       "      <td>235.696</td>\n",
       "      <td>7290000.0</td>\n",
       "      <td>128.641</td>\n",
       "      <td>128.641</td>\n",
       "      <td>267.305</td>\n",
       "      <td>411.703</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>707</td>\n",
       "      <td>356</td>\n",
       "      <td>62.8662</td>\n",
       "      <td>0.204366</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>838.251</td>\n",
       "      <td>0.841650</td>\n",
       "      <td>1944.226627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8069.33</td>\n",
       "      <td>220.951</td>\n",
       "      <td>732.682</td>\n",
       "      <td>639.272</td>\n",
       "      <td>329.783</td>\n",
       "      <td>12800000.0</td>\n",
       "      <td>104.248</td>\n",
       "      <td>104.248</td>\n",
       "      <td>231.448</td>\n",
       "      <td>413.026</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>419</td>\n",
       "      <td>116</td>\n",
       "      <td>55.3208</td>\n",
       "      <td>0.179837</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>442.287</td>\n",
       "      <td>1.445378</td>\n",
       "      <td>772.972198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17031.80</td>\n",
       "      <td>787.283</td>\n",
       "      <td>577.949</td>\n",
       "      <td>621.738</td>\n",
       "      <td>292.825</td>\n",
       "      <td>10200000.0</td>\n",
       "      <td>108.300</td>\n",
       "      <td>108.300</td>\n",
       "      <td>280.090</td>\n",
       "      <td>426.837</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>633</td>\n",
       "      <td>281</td>\n",
       "      <td>48.6026</td>\n",
       "      <td>0.157997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>669.885</td>\n",
       "      <td>0.928126</td>\n",
       "      <td>1616.109299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6710.65</td>\n",
       "      <td>989.219</td>\n",
       "      <td>549.029</td>\n",
       "      <td>769.896</td>\n",
       "      <td>308.886</td>\n",
       "      <td>11200000.0</td>\n",
       "      <td>137.896</td>\n",
       "      <td>137.896</td>\n",
       "      <td>256.777</td>\n",
       "      <td>416.086</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>550</td>\n",
       "      <td>193</td>\n",
       "      <td>75.0649</td>\n",
       "      <td>0.244021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>442.287</td>\n",
       "      <td>1.740716</td>\n",
       "      <td>841.396493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24057.80</td>\n",
       "      <td>1064.880</td>\n",
       "      <td>595.793</td>\n",
       "      <td>570.515</td>\n",
       "      <td>224.158</td>\n",
       "      <td>5990000.0</td>\n",
       "      <td>113.622</td>\n",
       "      <td>113.622</td>\n",
       "      <td>255.768</td>\n",
       "      <td>422.065</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>599</td>\n",
       "      <td>266</td>\n",
       "      <td>43.5273</td>\n",
       "      <td>0.141499</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>682.649</td>\n",
       "      <td>0.835737</td>\n",
       "      <td>1456.840216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pos_Y     Pos_X    Pos_Z      AMP      BGD         RES   SigmaX  \\\n",
       "0  28679.00   553.786  795.715  705.514  235.696   7290000.0  128.641   \n",
       "1   8069.33   220.951  732.682  639.272  329.783  12800000.0  104.248   \n",
       "2  17031.80   787.283  577.949  621.738  292.825  10200000.0  108.300   \n",
       "3   6710.65   989.219  549.029  769.896  308.886  11200000.0  137.896   \n",
       "4  24057.80  1064.880  595.793  570.515  224.158   5990000.0  113.622   \n",
       "\n",
       "    SigmaY   SigmaZ   Cent_Y     ...       Z_max  INT_raw  INT_filt   SC_det  \\\n",
       "0  128.641  267.305  411.703     ...           8      707       356  62.8662   \n",
       "1  104.248  231.448  413.026     ...           7      419       116  55.3208   \n",
       "2  108.300  280.090  426.837     ...           7      633       281  48.6026   \n",
       "3  137.896  256.777  416.086     ...           7      550       193  75.0649   \n",
       "4  113.622  255.768  422.065     ...           7      599       266  43.5273   \n",
       "\n",
       "   SC_det_norm  TH_det  TH_fit  target_amp  r_t_ratio    targ_dist  \n",
       "0     0.204366       1       1     838.251   0.841650  1944.226627  \n",
       "1     0.179837       1       1     442.287   1.445378   772.972198  \n",
       "2     0.157997       1       1     669.885   0.928126  1616.109299  \n",
       "3     0.244021       1       1     442.287   1.740716   841.396493  \n",
       "4     0.141499       1       1     682.649   0.835737  1456.840216  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating co-detection percentage for threshold = 500 nm\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p4s4r_AL_objs.csv\n",
      "codetection %:  0.0\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p4s3r_AL_objs.csv\n",
      "codetection %:  1.6203703703703702\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p3s3r_AL_objs.csv\n",
      "codetection %:  0.7357859531772575\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p3s4r_AL_objs.csv\n",
      "codetection %:  2.6474127557160045\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p2s4r_AL_objs.csv\n",
      "codetection %:  0.5154639175257731\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p4s5r_AL_objs.csv\n",
      "codetection %:  1.6096579476861168\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p1s4r_AL_objs.csv\n",
      "codetection %:  2.7501462843768287\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p2s3l_0001_AL_objs.csv\n",
      "codetection %:  0.0\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p5s4l_AL_objs.csv\n",
      "codetection %:  1.5122873345935728\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p5s3l_AL_objs.csv\n",
      "codetection %:  0.9592326139088728\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p2s3l_AL_objs.csv\n",
      "codetection %:  0.0\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p2s4l_AL_objs.csv\n",
      "codetection %:  1.0300429184549356\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p5s5l_AL_objs.csv\n",
      "codetection %:  0.33783783783783783\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p3s3l_AL_objs.csv\n",
      "codetection %:  1.078167115902965\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p4s4l_AL_objs.csv\n",
      "codetection %:  0.813953488372093\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p1s3l_AL_objs.csv\n",
      "codetection %:  1.7172086225794667\n",
      "20190621_eIF4eGFP_msp670_syp568_HRP_viol_stim_p1s2l_AL_objs.csv\n",
      "codetection %:  0.17543859649122806\n"
     ]
    }
   ],
   "source": [
    "############################################################################# \n",
    "# Calculate nearest neighbor distance between mRNA and granules          \n",
    "# Josh Titlow- July 11, 2019                                            \n",
    "#                                                                            \n",
    "# Requires results from 3D object counter              \n",
    "# Requires centroid file ('_FISH-QUANT_all_spots_yymmdd.csv') from a FQ bash run                                                      \n",
    "#                                                                           \n",
    "# Calculates % of spots within a specified range of distances \n",
    "#        \n",
    "# TODO                                                                     \n",
    "# -fix plotting                                                             \n",
    "#############################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# specify directory of files from 3D object counter\n",
    "indir = '/Users/joshtitlow/tmp/eif4e_experiment/raw_data/'\n",
    "infiles = os.listdir(indir)\n",
    "\n",
    "# specify smFISH centroid file ('_FISH-QUANT_all_spots_yymmdd.csv') from a FQ bash run\n",
    "smFISH_file = '/Users/joshtitlow/tmp/eif4e_experiment/_FISH-QUANT__all_spots_190710.txt'\n",
    "ref_file = pd.read_csv(smFISH_file, sep='\\t', header=13)\n",
    "\n",
    "# read the smFISH centroid file from the metadata header to get pixel size\n",
    "px_size = pd.read_csv(smFISH_file, sep='\\t', header=6, nrows=2)\n",
    "px_xy = float(px_size['Pix-XY'].iloc[0])\n",
    "px_z = float(px_size['Pix-Z'].iloc[0])\n",
    "\n",
    "#threshold_range = [50,100,150,200,250,300,350,400,450,500] \n",
    "threshold_range = [500]\n",
    "\n",
    "# create list to store data\n",
    "filename = []\n",
    "co_detect = []\n",
    "ref_spots = []\n",
    "targ_spots = []\n",
    "threshold = []\n",
    "NNdistance = []\n",
    "NNfile = []\n",
    "NNcentroid = []\n",
    "    \n",
    "def codetection():\n",
    "    for t in threshold_range:\n",
    "        print \"calculating co-detection percentage for threshold =\", t, \"nm\"\n",
    "\n",
    "        # loop through files\n",
    "        for i in infiles:\n",
    "\n",
    "            # create list to store amplitude of co-detected spot, ref/targ ratio, and target distance\n",
    "            targ_amp = []\n",
    "            targ_dist = []\n",
    "\n",
    "            if i.endswith('.csv'):\n",
    "                targ_file = os.path.join(indir,i)\n",
    "                targ_file = pd.read_csv(targ_file, header=0)\n",
    "                print i\n",
    "\n",
    "                # get centroid coordinates\n",
    "                xpos_targ = targ_file['XM'] * px_xy\n",
    "                ypos_targ = targ_file['YM'] * px_xy\n",
    "                zpos_targ = targ_file['ZM'] * px_z\n",
    "\n",
    "                # convert data into a numpy array\n",
    "                target_df = np.column_stack((xpos_targ,ypos_targ,zpos_targ))\n",
    "                #target_df = [target_df.Pos_Y.str.contains(\"SPOTS_END\") == False]\n",
    "\n",
    "                for index, row in ref_file.iterrows():\n",
    "\n",
    "                    if row['File'][:-7]+'objs.csv' == i:\n",
    "\n",
    "                        # get 3D position from X,Y,Z position columns\n",
    "                        pt  = float(row['Pos_X']), float(row['Pos_Y']), float(row['Pos_Z'])\n",
    "\n",
    "                        # find nearest neighbor and calculate distance\n",
    "                        distance,index = spatial.KDTree(target_df).query(pt)\n",
    "\n",
    "                        # add nearest neighbor amp and dist to a list\n",
    "                        #targ_amp.append(targ_file['AMP'].iloc[index])\n",
    "                        targ_dist.append(distance)\n",
    "                        NNdistance.append(distance)\n",
    "                        NNfile.append(i)\n",
    "                        NNcentroid.append(pt)\n",
    "\n",
    "                        # add lists to ref_file\n",
    "                        #ref_file['target_amp'] = targ_amp\n",
    "                        #ref_file['r_t_ratio'] = ref_file['AMP'].div(targ_amp)\n",
    "                        #ref_file['targ_dist'] = targ_dist\n",
    "                        #row['targ_dist'] = distance\n",
    "                        #ref_file.at[row['File'], 'targ_dist'] = str(distance)\n",
    "\n",
    "                # calculate co-detection percentage and add it to list\n",
    "                try:\n",
    "                    codetect = 100 * (sum(i < t for i in targ_dist) / (float(len(targ_dist))))\n",
    "                except:\n",
    "                    codetect = 0\n",
    "                print 'codetection %: ', codetect\n",
    "                co_detect.append(codetect)\n",
    "\n",
    "                # calculate number of spots and add to list, with filename\n",
    "                ref_spots.append(len(targ_dist))\n",
    "                targ_spots.append(len(targ_file))\n",
    "                filename.append(i)\n",
    "                threshold.append(t)\n",
    "\n",
    "                # write ref_file to csv\n",
    "                #ref_file.to_csv('test_list.csv', index=False)\n",
    "\n",
    "def random_codetection():\n",
    "    for t in threshold_range:\n",
    "        print \"calculating co-detection percentage for threshold =\", t, \"nm\"\n",
    "\n",
    "        # loop through files\n",
    "        for i in infiles:\n",
    "\n",
    "            # create list to store amplitude of co-detected spot, ref/targ ratio, and target distance\n",
    "            targ_amp = []\n",
    "            targ_dist = []\n",
    "\n",
    "            if i.endswith('.csv'):\n",
    "                targ_file = os.path.join(indir,i)\n",
    "                targ_file = pd.read_csv(targ_file, header=0)\n",
    "                print i\n",
    "\n",
    "                # get centroid coordinates\n",
    "                xpos_targ = targ_file['XM'] * px_xy\n",
    "                np.random.shuffle(xpos_targ)\n",
    "                ypos_targ = targ_file['YM'] * px_xy\n",
    "                np.random.shuffle(ypos_targ)\n",
    "                zpos_targ = targ_file['ZM'] * px_z\n",
    "                np.random.shuffle(zpos_targ)\n",
    "                \n",
    "                # convert data into a numpy array\n",
    "                target_df = np.column_stack((xpos_targ,ypos_targ,zpos_targ))\n",
    "                #target_df = [target_df.Pos_Y.str.contains(\"SPOTS_END\") == False]\n",
    "\n",
    "                for index, row in ref_file.iterrows():\n",
    "\n",
    "                    if row['File'][:-7]+'objs.csv' == i:\n",
    "\n",
    "                        # get 3D position from X,Y,Z position columns\n",
    "                        pt  = float(row['Pos_X']), float(row['Pos_Y']), float(row['Pos_Z'])\n",
    "\n",
    "                        # find nearest neighbor and calculate distance\n",
    "                        distance,index = spatial.KDTree(target_df).query(pt)\n",
    "\n",
    "                        # add nearest neighbor amp and dist to a list\n",
    "                        #targ_amp.append(targ_file['AMP'].iloc[index])\n",
    "                        targ_dist.append(distance)\n",
    "                        NNdistance.append(distance)\n",
    "                        NNfile.append(i)\n",
    "                        NNcentroid.append(pt)\n",
    "\n",
    "                        # add lists to ref_file\n",
    "                        #ref_file['target_amp'] = targ_amp\n",
    "                        #ref_file['r_t_ratio'] = ref_file['AMP'].div(targ_amp)\n",
    "                        #ref_file['targ_dist'] = targ_dist\n",
    "                        #row['targ_dist'] = distance\n",
    "                        #ref_file.at[row['File'], 'targ_dist'] = str(distance)\n",
    "\n",
    "                # calculate co-detection percentage and add it to list\n",
    "                try:\n",
    "                    codetect = 100 * (sum(i < t for i in targ_dist) / (float(len(targ_dist))))\n",
    "                except:\n",
    "                    codetect = 0\n",
    "                print 'codetection %: ', codetect\n",
    "                co_detect.append(codetect)\n",
    "\n",
    "                # calculate number of spots and add to list, with filename\n",
    "                ref_spots.append(len(targ_dist))\n",
    "                targ_spots.append(len(targ_file))\n",
    "                filename.append(i)\n",
    "                threshold.append(t)\n",
    "\n",
    "                # write ref_file to csv\n",
    "                #ref_file.to_csv('test_list.csv', index=False)    \n",
    "\n",
    "codetection()\n",
    "    \n",
    "# add data to dataframe and save\n",
    "df = pd.DataFrame({'filename':filename, 'threshold':threshold, 'co_detect':co_detect, 'ref_spots':ref_spots, 'targ_spots':targ_spots})\n",
    "df = df[['filename', 'threshold', 'co_detect', 'ref_spots', 'targ_spots']]\n",
    "df.to_csv('codetection_stats.csv', index=False)\n",
    "\n",
    "# add NNdistance data to separate dataframe and save\n",
    "df = pd.DataFrame({'filename':NNfile, 'distance':NNdistance, 'centroid':NNcentroid})\n",
    "df = df[['filename', 'distance', 'centroid']]\n",
    "df.to_csv('NN_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "threshold_range = [200,2000,20000,200000]\n",
    "x = threshold_range\n",
    "y = ([0.4, 1, 10, 50])\n",
    "plt.plot(x,y)\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(200, 0.010495166321788237), (2000, 8.391300996998295), (20000, 79.58979494157295), (200000, 100.0)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "test_file = pd.read_csv('codetection_stats.csv', header=0)\n",
    "thresholds = collections.OrderedDict.fromkeys(sorted(set(test_file['threshold'])), 0) \n",
    "\n",
    "for threshold in thresholds.keys():\n",
    "    codetect = []\n",
    "    for index, row in test_file.iterrows(): \n",
    "        if row['threshold'] == threshold:\n",
    "            codetect.append(row['co_detect'])\n",
    "    mean_codetect = np.mean(codetect)\n",
    "    thresholds.update({threshold: mean_codetect})\n",
    "\n",
    "print thresholds\n",
    "#plt.plot(list(thresholds),list(thresholds.values()))\n",
    "#plt.ylabel('some numbers')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.shuffle(ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(thresholds.values())\n",
    "x = list(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# specify the FQ centroid files and co-detection distance threshold in nm\n",
    "data = read_table('Results.txt', header=True, delim_whitespace=True)\n",
    "\n",
    "# create list to store data\n",
    "masked_signal = []\n",
    "co_detect = []\n",
    "ch1_spots = []\n",
    "ch2_spots = []\n",
    "threshold = []\n",
    "\n",
    "for index, row in ref_file.iterrows():\n",
    "    if row.endswith(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating co-detection percentage for threshold = 50 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 100 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 150 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 200 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 250 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 300 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 350 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 400 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 450 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n",
      "calculating co-detection percentage for threshold = 500 nm\n",
      "/Users/joshtitlow/tmp/smFISH_data/codetect/C4-758201.ome__spots.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# specify the FQ centroid files and co-detection distance threshold in nm\n",
    "indir = '/Users/joshtitlow/tmp/smFISH_data/codetect/'\n",
    "infiles = os.listdir(indir)\n",
    "\n",
    "threshold_range = [50,100,150,200,250,300,350,400,450,500] \n",
    "\n",
    "\n",
    "# create list to store data\n",
    "filename = []\n",
    "co_detect = []\n",
    "ch1_spots = []\n",
    "ch2_spots = []\n",
    "threshold = []\n",
    "\n",
    "for t in threshold_range:\n",
    "    print \"calculating co-detection percentage for threshold =\", t, \"nm\"\n",
    "    # loop through files\n",
    "    for i in infiles:\n",
    "        if i.startswith('C2'):\n",
    "            if i.endswith('spots.txt'):\n",
    "                ref_file = os.path.join(indir,i)\n",
    "                #print \"processing\", i, \"for threshold =\", t\n",
    "                ref_file = pd.read_csv(ref_file, sep='\\t', header=18)\n",
    "                #ref_file = ref_file[~ref_file.Pos_Y.str.contains(\"SPOTS_END\")]\n",
    "                targ_file = os.path.join(indir, 'C4'+i[2:])\n",
    "                print targ_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
